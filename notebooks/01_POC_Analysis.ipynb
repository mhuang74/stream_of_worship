{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POC Analysis: Worship Music Transition System\n",
    "\n",
    "**Version:** 0.1.0-poc  \n",
    "**Date:** 2024-12-30  \n",
    "**Goal:** Validate audio analysis pipeline with 3-5 Stream of Praise worship songs\n",
    "\n",
    "## Validation Goals\n",
    "\n",
    "1. **Tempo detection accuracy** (within ¬±5 BPM of manual count)\n",
    "2. **Key detection accuracy** (matches sheet music)\n",
    "3. **Structure segmentation quality** (meaningful boundaries)\n",
    "4. **Transition rendering quality** (natural sounding crossfades)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POC Analysis Started: 2025-12-30 22:50:03\n",
      "Audio directory: /workspace/poc_audio\n",
      "Output directory: /workspace/poc_output\n",
      "\n",
      "Found 3 audio files:\n",
      "  1. jesus.mp3\n",
      "  2. one_life.mp3\n",
      "  3. praise.mp3\n",
      "\n",
      "‚úì Good! 3 songs ready for analysis\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup and Imports\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Audio processing\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "\n",
    "# Data and math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Utilities\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration\n",
    "AUDIO_DIR = Path(\"poc_audio\")\n",
    "OUTPUT_DIR = Path(\"poc_output\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"POC Analysis Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Audio directory: {AUDIO_DIR.absolute()}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR.absolute()}\")\n",
    "print()\n",
    "\n",
    "# List available songs\n",
    "audio_files = sorted(list(AUDIO_DIR.glob(\"*.mp3\")) + list(AUDIO_DIR.glob(\"*.flac\")))\n",
    "print(f\"Found {len(audio_files)} audio files:\")\n",
    "for i, f in enumerate(audio_files, 1):\n",
    "    print(f\"  {i}. {f.name}\")\n",
    "    \n",
    "if len(audio_files) < 3:\n",
    "    print(\"\\n‚ö†Ô∏è  WARNING: Need at least 3 songs for meaningful POC validation\")\n",
    "    print(\"   Please add more audio files to poc_audio/ directory\")\n",
    "elif len(audio_files) > 5:\n",
    "    print(\"\\n‚ö†Ô∏è  NOTE: More than 5 songs found. POC will analyze all.\")\n",
    "else:\n",
    "    print(f\"\\n‚úì Good! {len(audio_files)} songs ready for analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Feature extraction function defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Feature Extraction Function\n",
    "\n",
    "def analyze_song(filepath):\n",
    "    \"\"\"\n",
    "    Run complete feature extraction on a single song.\n",
    "    \n",
    "    Returns dictionary with:\n",
    "    - Basic metadata (filename, duration)\n",
    "    - Tempo analysis (BPM, beats)\n",
    "    - Key detection (key, mode, confidence)\n",
    "    - Energy metrics (RMS, loudness dB)\n",
    "    - Structure (sections, boundaries)\n",
    "    - Raw data for visualization\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Analyzing: {filepath.name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # === LOAD AUDIO ===\n",
    "    y, sr = librosa.load(filepath, sr=22050, mono=True)\n",
    "    duration = librosa.get_duration(y=y, sr=sr)\n",
    "    print(f\"‚úì Loaded: {duration:.1f}s @ {sr} Hz\")\n",
    "    \n",
    "    # === TEMPO DETECTION ===\n",
    "    tempo_librosa, beats_frames = librosa.beat.beat_track(\n",
    "        y=y, sr=sr, start_bpm=80, units='frames'\n",
    "    )\n",
    "    beats_time = librosa.frames_to_time(beats_frames, sr=sr)\n",
    "    print(f\"‚úì Tempo: {tempo_librosa:.1f} BPM ({len(beats_time)} beats detected)\")\n",
    "    \n",
    "    # === KEY DETECTION ===\n",
    "    chroma = librosa.feature.chroma_cqt(y=y, sr=sr, hop_length=512)\n",
    "    chroma_avg = np.mean(chroma, axis=1)\n",
    "    \n",
    "    # Krumhansl-Schmuckler key profiles\n",
    "    keys = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
    "    major_profile = np.array([6.35, 2.23, 3.48, 2.33, 4.38, 4.09, \n",
    "                              2.52, 5.19, 2.39, 3.66, 2.29, 2.88])\n",
    "    minor_profile = np.array([6.33, 2.68, 3.52, 5.38, 2.60, 3.53,\n",
    "                              2.54, 4.75, 3.98, 2.69, 3.34, 3.17])\n",
    "    \n",
    "    correlations = []\n",
    "    for shift in range(12):\n",
    "        # Major key correlation\n",
    "        major_corr = np.corrcoef(\n",
    "            chroma_avg, \n",
    "            np.roll(major_profile, shift)\n",
    "        )[0, 1]\n",
    "        correlations.append(('major', keys[shift], major_corr))\n",
    "        \n",
    "        # Minor key correlation\n",
    "        minor_corr = np.corrcoef(\n",
    "            chroma_avg,\n",
    "            np.roll(minor_profile, shift)\n",
    "        )[0, 1]\n",
    "        correlations.append(('minor', keys[shift], minor_corr))\n",
    "    \n",
    "    best_key = max(correlations, key=lambda x: x[2])\n",
    "    mode, key, confidence = best_key\n",
    "    print(f\"‚úì Key: {key} {mode} (confidence: {confidence:.3f})\")\n",
    "    \n",
    "    # === ENERGY ANALYSIS ===\n",
    "    rms = librosa.feature.rms(y=y, frame_length=2048, hop_length=512)[0]\n",
    "    rms_db = librosa.amplitude_to_db(rms, ref=np.max)\n",
    "    loudness_mean = float(np.mean(rms_db))\n",
    "    loudness_std = float(np.std(rms_db))\n",
    "    \n",
    "    # Spectral centroid (brightness)\n",
    "    centroid = librosa.feature.spectral_centroid(y=y, sr=sr)[0]\n",
    "    centroid_mean = float(np.mean(centroid))\n",
    "    \n",
    "    print(f\"‚úì Energy: {loudness_mean:.1f} dB (¬±{loudness_std:.1f})\")\n",
    "    print(f\"  Brightness: {centroid_mean:.0f} Hz\")\n",
    "    \n",
    "    # === STRUCTURE SEGMENTATION ===\n",
    "    # Compute recurrence matrix\n",
    "    chroma_seg = librosa.feature.chroma_cqt(y=y, sr=sr, hop_length=512)\n",
    "    rec_matrix = librosa.segment.recurrence_matrix(\n",
    "        chroma_seg, \n",
    "        mode='affinity',\n",
    "        metric='cosine'\n",
    "    )\n",
    "    \n",
    "    # Detect boundaries using novelty\n",
    "    novelty = librosa.segment.timelag_filter(rec_matrix, size=32)\n",
    "    peaks = librosa.util.peak_pick(\n",
    "        novelty,\n",
    "        pre_max=5, post_max=5,\n",
    "        pre_avg=5, post_avg=5,\n",
    "        delta=0.1, wait=10\n",
    "    )\n",
    "    \n",
    "    boundary_times = librosa.frames_to_time(peaks, sr=sr, hop_length=512)\n",
    "    boundaries = [0.0] + boundary_times.tolist() + [duration]\n",
    "    \n",
    "    # Label sections (simplified heuristic)\n",
    "    sections = []\n",
    "    for i in range(len(boundaries) - 1):\n",
    "        start = boundaries[i]\n",
    "        end = boundaries[i + 1]\n",
    "        sec_duration = end - start\n",
    "        \n",
    "        if i == 0 and sec_duration < 15:\n",
    "            label = 'intro'\n",
    "        elif i == len(boundaries) - 2 and sec_duration < 20:\n",
    "            label = 'outro'\n",
    "        elif sec_duration > 30:\n",
    "            label = 'verse'\n",
    "        else:\n",
    "            label = 'chorus'\n",
    "            \n",
    "        sections.append({\n",
    "            'label': label,\n",
    "            'start': start,\n",
    "            'end': end,\n",
    "            'duration': sec_duration\n",
    "        })\n",
    "    \n",
    "    print(f\"‚úì Structure: {len(sections)} sections detected\")\n",
    "    for sec in sections:\n",
    "        print(f\"  {sec['start']:.1f}s - {sec['end']:.1f}s: {sec['label']} ({sec['duration']:.1f}s)\")\n",
    "    \n",
    "    # === RETURN RESULTS ===\n",
    "    return {\n",
    "        # Metadata\n",
    "        'filename': filepath.name,\n",
    "        'filepath': str(filepath),\n",
    "        'duration': duration,\n",
    "        \n",
    "        # Rhythm\n",
    "        'tempo': float(tempo_librosa),\n",
    "        'num_beats': len(beats_time),\n",
    "        'beats': beats_time.tolist()[:100],  # Store first 100 beats\n",
    "        \n",
    "        # Harmony\n",
    "        'key': key,\n",
    "        'mode': mode,\n",
    "        'key_confidence': float(confidence),\n",
    "        'full_key': f\"{key} {mode}\",\n",
    "        \n",
    "        # Energy\n",
    "        'loudness_db': loudness_mean,\n",
    "        'loudness_std': loudness_std,\n",
    "        'spectral_centroid': centroid_mean,\n",
    "        \n",
    "        # Structure\n",
    "        'num_sections': len(sections),\n",
    "        'sections': sections,\n",
    "        'boundaries': boundaries,\n",
    "        \n",
    "        # Raw data for visualization (prefixed with _)\n",
    "        '_y': y,\n",
    "        '_sr': sr,\n",
    "        '_chroma': chroma,\n",
    "        '_rms': rms,\n",
    "        '_beats': beats_time,\n",
    "        '_novelty': novelty\n",
    "    }\n",
    "\n",
    "print(\"‚úì Feature extraction function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Analyzing: jesus.mp3\n",
      "======================================================================\n",
      "‚úì Loaded: 283.5s @ 22050 Hz\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Analyze All Songs\n",
    "\n",
    "# Process all songs\n",
    "results = []\n",
    "errors = []\n",
    "\n",
    "for audio_file in audio_files:\n",
    "    try:\n",
    "        result = analyze_song(audio_file)\n",
    "        results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ERROR processing {audio_file.name}: {str(e)}\")\n",
    "        errors.append({'file': audio_file.name, 'error': str(e)})\n",
    "\n",
    "# Create summary DataFrame\n",
    "df_summary = pd.DataFrame([\n",
    "    {k: v for k, v in r.items() if not k.startswith('_')} \n",
    "    for r in results\n",
    "])\n",
    "\n",
    "# Display summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ANALYSIS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "if not df_summary.empty:\n",
    "    print(df_summary[['filename', 'duration', 'tempo', 'full_key', 'loudness_db', 'num_sections']].to_string(index=False))\n",
    "\n",
    "if errors:\n",
    "    print(f\"\\n‚ö†Ô∏è  {len(errors)} files failed to process:\")\n",
    "    for err in errors:\n",
    "        print(f\"  - {err['file']}: {err['error']}\")\n",
    "\n",
    "# Save summary to CSV\n",
    "if not df_summary.empty:\n",
    "    csv_path = OUTPUT_DIR / \"poc_summary.csv\"\n",
    "    df_summary.to_csv(csv_path, index=False)\n",
    "    print(f\"\\n‚úì Summary saved to: {csv_path}\")\n",
    "\n",
    "    # Save full results to JSON (including raw data references)\n",
    "    json_path = OUTPUT_DIR / \"poc_full_results.json\"\n",
    "    results_serializable = [\n",
    "        {k: v for k, v in r.items() if not k.startswith('_')}\n",
    "        for r in results\n",
    "    ]\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(results_serializable, f, indent=2)\n",
    "    print(f\"‚úì Full results saved to: {json_path}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No songs were successfully analyzed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Visualizations\n",
    "\n",
    "if not results:\n",
    "    print(\"‚ö†Ô∏è  No results to visualize. Please ensure audio files are in poc_audio/ directory.\")\n",
    "else:\n",
    "    # Create comprehensive visualization\n",
    "    n_songs = len(results)\n",
    "    fig, axes = plt.subplots(n_songs, 3, figsize=(18, 5*n_songs))\n",
    "\n",
    "    # Handle single song case\n",
    "    if n_songs == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "\n",
    "    for idx, result in enumerate(results):\n",
    "        y = result['_y']\n",
    "        sr = result['_sr']\n",
    "        chroma = result['_chroma']\n",
    "        rms = result['_rms']\n",
    "        beats = result['_beats']\n",
    "        \n",
    "        # === Panel 1: Waveform with beats ===\n",
    "        ax = axes[idx, 0]\n",
    "        times = np.arange(len(y)) / sr\n",
    "        ax.plot(times, y, alpha=0.7, linewidth=0.5)\n",
    "        \n",
    "        # Mark beats\n",
    "        for beat in beats[:50]:  # First 50 beats for clarity\n",
    "            ax.axvline(beat, color='red', alpha=0.3, linewidth=1)\n",
    "        \n",
    "        ax.set_title(f\"{result['filename']}\\nWaveform + Beats\", fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel(\"Time (s)\")\n",
    "        ax.set_ylabel(\"Amplitude\")\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # === Panel 2: Chromagram ===\n",
    "        ax = axes[idx, 1]\n",
    "        img = librosa.display.specshow(\n",
    "            chroma, \n",
    "            sr=sr, \n",
    "            x_axis='time', \n",
    "            y_axis='chroma',\n",
    "            hop_length=512,\n",
    "            ax=ax,\n",
    "            cmap='coolwarm'\n",
    "        )\n",
    "        ax.set_title(f\"Chromagram\\nDetected Key: {result['full_key']} (conf: {result['key_confidence']:.2f})\", \n",
    "                     fontsize=12, fontweight='bold')\n",
    "        plt.colorbar(img, ax=ax, format='%.2f')\n",
    "        \n",
    "        # === Panel 3: Energy Profile ===\n",
    "        ax = axes[idx, 2]\n",
    "        rms_times = librosa.times_like(rms, sr=sr, hop_length=512)\n",
    "        ax.plot(rms_times, rms, color='purple', linewidth=2)\n",
    "        ax.fill_between(rms_times, 0, rms, alpha=0.3, color='purple')\n",
    "        \n",
    "        # Mark sections\n",
    "        for section in result['sections']:\n",
    "            color = {'intro': 'green', 'verse': 'blue', 'chorus': 'orange', 'outro': 'red'}.get(section['label'], 'gray')\n",
    "            ax.axvspan(section['start'], section['end'], alpha=0.2, color=color, label=section['label'])\n",
    "        \n",
    "        ax.set_title(f\"Energy Profile\\n{result['tempo']:.1f} BPM, {result['loudness_db']:.1f} dB\", \n",
    "                     fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel(\"Time (s)\")\n",
    "        ax.set_ylabel(\"RMS Energy\")\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Legend (only unique labels)\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        by_label = dict(zip(labels, handles))\n",
    "        ax.legend(by_label.values(), by_label.keys(), loc='upper right', fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    viz_path = OUTPUT_DIR / \"poc_analysis_visualizations.png\"\n",
    "    plt.savefig(viz_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"‚úì Visualizations saved to: {viz_path}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Compatibility Analysis\n",
    "\n",
    "def calculate_compatibility(song_a, song_b):\n",
    "    \"\"\"\n",
    "    Calculate compatibility scores between two songs.\n",
    "    \n",
    "    Scoring:\n",
    "    - Tempo: 100 if <5% diff, scales down to 0 at >20% diff\n",
    "    - Key: 100 if same, 80 if compatible, 40 otherwise\n",
    "    - Energy: Based on loudness difference\n",
    "    - Overall: Weighted average (40% tempo + 40% key + 20% energy)\n",
    "    \"\"\"\n",
    "    # === TEMPO COMPATIBILITY ===\n",
    "    tempo_diff_pct = abs(song_a['tempo'] - song_b['tempo']) / max(song_a['tempo'], song_b['tempo'])\n",
    "    \n",
    "    if tempo_diff_pct < 0.05:\n",
    "        tempo_score = 100.0\n",
    "    elif tempo_diff_pct < 0.10:\n",
    "        tempo_score = 100 - (tempo_diff_pct - 0.05) * 400  # Linear 100->80\n",
    "    elif tempo_diff_pct < 0.15:\n",
    "        tempo_score = 80 - (tempo_diff_pct - 0.10) * 400   # Linear 80->60\n",
    "    elif tempo_diff_pct < 0.20:\n",
    "        tempo_score = 60 - (tempo_diff_pct - 0.15) * 1200  # Linear 60->0\n",
    "    else:\n",
    "        tempo_score = 0.0\n",
    "    \n",
    "    # === KEY COMPATIBILITY (SIMPLIFIED) ===\n",
    "    # Full implementation would use Camelot wheel\n",
    "    if song_a['key'] == song_b['key'] and song_a['mode'] == song_b['mode']:\n",
    "        key_score = 100.0\n",
    "    elif song_a['key'] == song_b['key']:  # Same root, different mode (relative)\n",
    "        key_score = 80.0\n",
    "    else:\n",
    "        # Simplified compatible key mapping\n",
    "        compatible_keys = {\n",
    "            'C': ['G', 'F', 'Am'],\n",
    "            'G': ['D', 'C', 'Em'],\n",
    "            'D': ['A', 'G', 'Bm'],\n",
    "            'A': ['E', 'D', 'F#m'],\n",
    "            'E': ['B', 'A', 'C#m'],\n",
    "            'F': ['C', 'Bb', 'Dm'],\n",
    "        }\n",
    "        key_a = f\"{song_a['key']}{' ' if song_a['mode'] == 'major' else 'm'}\"\n",
    "        key_b = f\"{song_b['key']}{' ' if song_b['mode'] == 'major' else 'm'}\"\n",
    "        \n",
    "        if key_b in compatible_keys.get(song_a['key'], []):\n",
    "            key_score = 70.0\n",
    "        else:\n",
    "            key_score = 40.0\n",
    "    \n",
    "    # === ENERGY COMPATIBILITY ===\n",
    "    energy_diff = abs(song_a['loudness_db'] - song_b['loudness_db'])\n",
    "    energy_score = max(0, 100 - energy_diff * 5)  # 5dB diff = 75 score\n",
    "    \n",
    "    # === OVERALL SCORE ===\n",
    "    overall_score = (tempo_score * 0.40 + \n",
    "                     key_score * 0.40 + \n",
    "                     energy_score * 0.20)\n",
    "    \n",
    "    return {\n",
    "        'song_a': song_a['filename'],\n",
    "        'song_b': song_b['filename'],\n",
    "        'tempo_a': song_a['tempo'],\n",
    "        'tempo_b': song_b['tempo'],\n",
    "        'tempo_diff_pct': tempo_diff_pct * 100,\n",
    "        'tempo_score': round(tempo_score, 1),\n",
    "        'key_a': song_a['full_key'],\n",
    "        'key_b': song_b['full_key'],\n",
    "        'key_score': round(key_score, 1),\n",
    "        'energy_diff_db': round(energy_diff, 1),\n",
    "        'energy_score': round(energy_score, 1),\n",
    "        'overall_score': round(overall_score, 1)\n",
    "    }\n",
    "\n",
    "if len(results) >= 2:\n",
    "    # Calculate all pairwise compatibilities\n",
    "    compatibilities = []\n",
    "    for i, song_a in enumerate(results):\n",
    "        for j, song_b in enumerate(results):\n",
    "            if i < j:  # Avoid self-comparison and duplicates\n",
    "                compat = calculate_compatibility(song_a, song_b)\n",
    "                compatibilities.append(compat)\n",
    "\n",
    "    # Create compatibility DataFrame\n",
    "    df_compat = pd.DataFrame(compatibilities)\n",
    "    df_compat_sorted = df_compat.sort_values('overall_score', ascending=False)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"COMPATIBILITY MATRIX\")\n",
    "    print(\"=\"*70)\n",
    "    print(df_compat_sorted.to_string(index=False))\n",
    "\n",
    "    # Save to CSV\n",
    "    compat_csv_path = OUTPUT_DIR / \"poc_compatibility_scores.csv\"\n",
    "    df_compat_sorted.to_csv(compat_csv_path, index=False)\n",
    "    print(f\"\\n‚úì Compatibility matrix saved to: {compat_csv_path}\")\n",
    "\n",
    "    # Visualize compatibility heatmap\n",
    "    if len(results) >= 2:\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        \n",
    "        # Create pivot table for heatmap\n",
    "        song_names = [r['filename'] for r in results]\n",
    "        matrix = np.zeros((len(song_names), len(song_names)))\n",
    "        \n",
    "        for compat in compatibilities:\n",
    "            i = next(idx for idx, r in enumerate(results) if r['filename'] == compat['song_a'])\n",
    "            j = next(idx for idx, r in enumerate(results) if r['filename'] == compat['song_b'])\n",
    "            matrix[i, j] = compat['overall_score']\n",
    "            matrix[j, i] = compat['overall_score']\n",
    "        \n",
    "        sns.heatmap(matrix, annot=True, fmt='.1f', cmap='RdYlGn', vmin=0, vmax=100,\n",
    "                    xticklabels=song_names, yticklabels=song_names)\n",
    "        plt.title(\"Song Compatibility Matrix\\n(Overall Score 0-100)\", fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        heatmap_path = OUTPUT_DIR / \"poc_compatibility_heatmap.png\"\n",
    "        plt.savefig(heatmap_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"‚úì Heatmap saved to: {heatmap_path}\")\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Need at least 2 songs to analyze compatibility\")\n",
    "    compatibilities = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Simple Transition Prototype\n",
    "\n",
    "def create_simple_crossfade(song_a_path, song_b_path, crossfade_duration=8.0):\n",
    "    \"\"\"\n",
    "    Create equal-power crossfade between two songs.\n",
    "    \n",
    "    Algorithm:\n",
    "    1. Load stereo audio at 44100 Hz\n",
    "    2. Extract outro of song A (last N seconds)\n",
    "    3. Extract intro of song B (first N seconds)\n",
    "    4. Apply equal-power fade curves (sqrt for energy preservation)\n",
    "    5. Mix faded segments\n",
    "    \n",
    "    Returns: (transition_audio, sample_rate)\n",
    "    \"\"\"\n",
    "    print(f\"\\nCreating {crossfade_duration}s crossfade...\")\n",
    "    \n",
    "    # Load stereo audio for higher quality transition\n",
    "    y_a, sr = librosa.load(song_a_path, sr=44100, mono=False)\n",
    "    y_b, sr_b = librosa.load(song_b_path, sr=44100, mono=False)\n",
    "    \n",
    "    # Ensure stereo (2 channels)\n",
    "    if y_a.ndim == 1:\n",
    "        y_a = np.stack([y_a, y_a])\n",
    "    if y_b.ndim == 1:\n",
    "        y_b = np.stack([y_b, y_b])\n",
    "    \n",
    "    crossfade_samples = int(crossfade_duration * sr)\n",
    "    \n",
    "    # Extract segments\n",
    "    outro = y_a[:, -crossfade_samples:]  # Last N seconds of A\n",
    "    intro = y_b[:, :crossfade_samples]   # First N seconds of B\n",
    "    \n",
    "    print(f\"  Outro shape: {outro.shape}\")\n",
    "    print(f\"  Intro shape: {intro.shape}\")\n",
    "    \n",
    "    # Equal-power crossfade curves\n",
    "    fade_curve = np.linspace(0, 1, crossfade_samples)\n",
    "    fade_out = np.sqrt(1 - fade_curve)  # Starts at 1, ends at 0\n",
    "    fade_in = np.sqrt(fade_curve)       # Starts at 0, ends at 1\n",
    "    \n",
    "    # Apply fades to both channels\n",
    "    outro_faded = outro * fade_out\n",
    "    intro_faded = intro * fade_in\n",
    "    \n",
    "    # Mix\n",
    "    transition = outro_faded + intro_faded\n",
    "    \n",
    "    return transition, sr\n",
    "\n",
    "# Select best compatible pair\n",
    "if len(compatibilities) > 0:\n",
    "    best_pair = df_compat_sorted.iloc[0]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TRANSITION PROTOTYPE\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Creating transition between most compatible pair:\")\n",
    "    print(f\"  Song A: {best_pair['song_a']}\")\n",
    "    print(f\"  Song B: {best_pair['song_b']}\")\n",
    "    print(f\"  Overall compatibility: {best_pair['overall_score']:.1f}/100\")\n",
    "    print(f\"  Tempo match: {best_pair['tempo_score']:.1f}/100 ({best_pair['tempo_a']:.1f} -> {best_pair['tempo_b']:.1f} BPM)\")\n",
    "    print(f\"  Key match: {best_pair['key_score']:.1f}/100 ({best_pair['key_a']} -> {best_pair['key_b']})\")\n",
    "    \n",
    "    # Find file paths\n",
    "    song_a_path = AUDIO_DIR / best_pair['song_a']\n",
    "    song_b_path = AUDIO_DIR / best_pair['song_b']\n",
    "    \n",
    "    # Create transition\n",
    "    transition, sr = create_simple_crossfade(song_a_path, song_b_path, crossfade_duration=10.0)\n",
    "    \n",
    "    # Save transition audio\n",
    "    safe_name_a = best_pair['song_a'].replace('.mp3', '').replace('.flac', '')\n",
    "    safe_name_b = best_pair['song_b'].replace('.mp3', '').replace('.flac', '')\n",
    "    transition_filename = f\"transition_{safe_name_a}_to_{safe_name_b}.flac\"\n",
    "    transition_path = OUTPUT_DIR / transition_filename\n",
    "    \n",
    "    sf.write(transition_path, transition.T, sr)\n",
    "    print(f\"\\n‚úì Transition audio saved to: {transition_path}\")\n",
    "    print(f\"  Duration: {transition.shape[1] / sr:.1f}s\")\n",
    "    print(f\"  Channels: {transition.shape[0]}\")\n",
    "    print(f\"  Sample rate: {sr} Hz\")\n",
    "    \n",
    "    # Visualize transition waveform\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "    \n",
    "    # Left channel\n",
    "    ax = axes[0]\n",
    "    times = np.arange(transition.shape[1]) / sr\n",
    "    ax.plot(times, transition[0, :], linewidth=0.5, color='blue')\n",
    "    ax.fill_between(times, 0, transition[0, :], alpha=0.3, color='blue')\n",
    "    ax.set_title(\"Transition Waveform - Left Channel\", fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel(\"Amplitude\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.axvline(5.0, color='red', linestyle='--', label='Crossfade midpoint')\n",
    "    ax.legend()\n",
    "    \n",
    "    # Right channel\n",
    "    ax = axes[1]\n",
    "    ax.plot(times, transition[1, :], linewidth=0.5, color='green')\n",
    "    ax.fill_between(times, 0, transition[1, :], alpha=0.3, color='green')\n",
    "    ax.set_title(\"Transition Waveform - Right Channel\", fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel(\"Time (s)\")\n",
    "    ax.set_ylabel(\"Amplitude\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.axvline(5.0, color='red', linestyle='--', label='Crossfade midpoint')\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    waveform_path = OUTPUT_DIR / \"transition_waveform.png\"\n",
    "    plt.savefig(waveform_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"‚úì Waveform visualization saved to: {waveform_path}\")\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No song pairs to analyze (need at least 2 songs)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: POC Summary and Next Steps\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"POC SUMMARY REPORT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if results:\n",
    "    # Statistics\n",
    "    print(f\"\\nüìä Analysis Statistics:\")\n",
    "    print(f\"  Total songs analyzed: {len(results)}\")\n",
    "    print(f\"  Total errors: {len(errors)}\")\n",
    "    print(f\"  Tempo range: {df_summary['tempo'].min():.1f} - {df_summary['tempo'].max():.1f} BPM\")\n",
    "    print(f\"  Keys detected: {', '.join(sorted(df_summary['full_key'].unique()))}\")\n",
    "    print(f\"  Average duration: {df_summary['duration'].mean():.1f}s ({df_summary['duration'].mean()/60:.1f} min)\")\n",
    "    print(f\"  Average sections per song: {df_summary['num_sections'].mean():.1f}\")\n",
    "\n",
    "    if len(compatibilities) > 0:\n",
    "        print(f\"\\nüîó Compatibility Analysis:\")\n",
    "        print(f\"  Total pairings analyzed: {len(compatibilities)}\")\n",
    "        print(f\"  Best compatibility score: {df_compat['overall_score'].max():.1f}/100\")\n",
    "        print(f\"  Worst compatibility score: {df_compat['overall_score'].min():.1f}/100\")\n",
    "        print(f\"  Average compatibility: {df_compat['overall_score'].mean():.1f}/100\")\n",
    "        print(f\"  High-quality pairs (>70): {len(df_compat[df_compat['overall_score'] > 70])}\")\n",
    "\n",
    "    # Outputs generated\n",
    "    print(f\"\\nüìÅ Outputs Generated:\")\n",
    "    outputs = [\n",
    "        (\"poc_summary.csv\", \"Summary table (CSV)\"),\n",
    "        (\"poc_full_results.json\", \"Full analysis results (JSON)\"),\n",
    "        (\"poc_analysis_visualizations.png\", \"Song visualizations (waveform, chroma, energy)\"),\n",
    "    ]\n",
    "    \n",
    "    if len(compatibilities) > 0:\n",
    "        outputs.extend([\n",
    "            (\"poc_compatibility_scores.csv\", \"Compatibility matrix (CSV)\"),\n",
    "            (\"poc_compatibility_heatmap.png\", \"Compatibility heatmap\"),\n",
    "        ])\n",
    "        if 'transition_filename' in locals():\n",
    "            outputs.extend([\n",
    "                (transition_filename, \"Sample transition audio (FLAC)\"),\n",
    "                (\"transition_waveform.png\", \"Transition waveform visualization\")\n",
    "            ])\n",
    "\n",
    "    for idx, (filename, description) in enumerate(outputs, 1):\n",
    "        filepath = OUTPUT_DIR / filename\n",
    "        if filepath.exists():\n",
    "            size_kb = filepath.stat().st_size / 1024\n",
    "            print(f\"  {idx}. {filename}\")\n",
    "            print(f\"     {description} ({size_kb:.1f} KB)\")\n",
    "\n",
    "    # Validation questions\n",
    "    print(f\"\\n‚úÖ VALIDATION CHECKLIST:\")\n",
    "    print(f\"Please manually verify the following:\")\n",
    "    print(f\"\\n1. Tempo Accuracy:\")\n",
    "    print(f\"   - Listen to each song and tap along to count BPM\")\n",
    "    print(f\"   - Compare to detected tempo (should be within ¬±5 BPM)\")\n",
    "    print(f\"   - Detected tempos: {dict(zip(df_summary['filename'], df_summary['tempo'].round(1)))}\")\n",
    "\n",
    "    print(f\"\\n2. Key Detection:\")\n",
    "    print(f\"   - Compare detected keys to sheet music (if available)\")\n",
    "    print(f\"   - Or use external key detection tools (e.g., Mixed In Key)\")\n",
    "    print(f\"   - Detected keys: {dict(zip(df_summary['filename'], df_summary['full_key']))}\")\n",
    "\n",
    "    print(f\"\\n3. Transition Quality:\")\n",
    "    if len(compatibilities) > 0 and 'transition_path' in locals():\n",
    "        print(f\"   - Listen to: {transition_path}\")\n",
    "        print(f\"   - Does the crossfade sound natural?\")\n",
    "        print(f\"   - Are there any jarring discontinuities?\")\n",
    "        print(f\"   - Does the tempo/key mismatch create dissonance?\")\n",
    "    else:\n",
    "        print(f\"   - (Need at least 2 songs to test transitions)\")\n",
    "\n",
    "    print(f\"\\n4. Section Boundaries:\")\n",
    "    print(f\"   - Review visualizations: poc_analysis_visualizations.png\")\n",
    "    print(f\"   - Do colored regions align with actual song structure?\")\n",
    "    print(f\"   - Are intro/outro/verse/chorus labels reasonable?\")\n",
    "\n",
    "    # Next steps\n",
    "    print(f\"\\nüöÄ NEXT STEPS:\")\n",
    "    print(f\"\\n‚úì POC Complete - Ready for Phase 2 if validation passes!\")\n",
    "    print(f\"\\nIf validation is successful:\")\n",
    "    print(f\"  1. Document any accuracy issues or edge cases\")\n",
    "    print(f\"  2. Proceed to Phase 2: Core Infrastructure\")\n",
    "    print(f\"     - Implement PostgreSQL database schema\")\n",
    "    print(f\"     - Build modular preprocessing pipeline\")\n",
    "    print(f\"     - Add madmom beat tracking for improved accuracy\")\n",
    "    print(f\"     - Implement Camelot wheel for key compatibility\")\n",
    "    print(f\"  3. Reference: specs/worship-music-transition-system-design.md\")\n",
    "\n",
    "    print(f\"\\nIf validation fails:\")\n",
    "    print(f\"  1. Document specific failure cases\")\n",
    "    print(f\"  2. Adjust analysis parameters (see Cell 2)\")\n",
    "    print(f\"  3. Consider alternative algorithms:\")\n",
    "    print(f\"     - madmom for tempo (already in pyproject.toml)\")\n",
    "    print(f\"     - Essentia for key detection\")\n",
    "    print(f\"     - Manual boundary annotation\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  No audio files were analyzed.\")\n",
    "    print(f\"\\nPlease:\")\n",
    "    print(f\"  1. Place 3-5 audio files (MP3/FLAC) in: {AUDIO_DIR.absolute()}\")\n",
    "    print(f\"  2. Re-run this notebook\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(f\"POC Analysis Completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
